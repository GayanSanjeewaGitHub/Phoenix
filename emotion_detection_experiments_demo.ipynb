{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet arize-phoenix pandas pyarrow openai anthropic\n",
    "%pip install --quiet openinference-instrumentation-openai opentelemetry-sdk opentelemetry-exporter-otlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Variables & Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\") is None:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"üîë Enter your OpenAI API key: \")\n",
    "    \n",
    "if not (PHOENIX_API_KEY := os.getenv(\"PHOENIX_API_KEY\")):\n",
    "    PHOENIX_API_KEY = getpass(\"üîë Enter your Phoenix API key: \")\n",
    "\n",
    "os.environ[\"PHOENIX_API_KEY\"] = PHOENIX_API_KEY\n",
    "\n",
    "if os.environ.get(\"ANTHROPIC_API_KEY\") is None:\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = getpass(\"üîë Enter your Anthropic API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import (\n",
    "    OTLPSpanExporter as HTTPSpanExporter,\n",
    ")\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "import phoenix as px\n",
    "\n",
    "# Add Phoenix API Key for tracing\n",
    "PHOENIX_API_KEY = os.environ[\"PHOENIX_API_KEY\"]\n",
    "\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\"\n",
    "\n",
    "# Add Phoenix\n",
    "span_phoenix_processor = SimpleSpanProcessor(HTTPSpanExporter(endpoint=\"https://app.phoenix.arize.com/v1/traces\"))\n",
    "\n",
    "# Add them to the tracer\n",
    "tracer_provider = trace_sdk.TracerProvider()\n",
    "tracer_provider.add_span_processor(span_processor=span_phoenix_processor)\n",
    "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
    "OpenAIInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prediction_id                         text predicted_emotion\n",
      "0              1         I am so happy today!         happiness\n",
      "1              2  This is the worst day ever.             anger\n",
      "2              3  I feel so calm and relaxed.              calm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Parquet file into a DataFrame\n",
    "# file_path = 'emotion_classification.parquet'\n",
    "# df = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/raw/train-00000-of-00001.parquet\")\n",
    "\n",
    "# df = pd.read_parquet(file_path)\n",
    "\n",
    "data = {\n",
    "    \"prediction_id\": [1, 2, 3],\n",
    "    \"text\": [\"I am so happy today!\", \"This is the worst day ever.\", \"I feel so calm and relaxed.\"],\n",
    "    \"predicted_emotion\": [\"happiness\", \"anger\", \"calm\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_emotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am so happy today!</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the worst day ever.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I feel so calm and relaxed.</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text predicted_emotion\n",
       "prediction_id                                               \n",
       "1                     I am so happy today!         happiness\n",
       "2              This is the worst day ever.             anger\n",
       "3              I feel so calm and relaxed.              calm"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[:20]\n",
    "df = df[[\"prediction_id\", \"text\", \"predicted_emotion\"]]\n",
    "df.set_index(\"prediction_id\", inplace=True)\n",
    "emotions= df['predicted_emotion'].unique()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\utilities\\client.py:34: UserWarning: The Phoenix server has an unknown version and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\utilities\\client.py:54: UserWarning: The Phoenix server (6.0.0) and client (6.1.0) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Examples uploaded: https://app.phoenix.arize.com/datasets/RGF0YXNldDoy/examples\n",
      "üóÑÔ∏è Dataset version ID: RGF0YXNldFZlcnNpb246Mg==\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "dataset = px.Client().upload_dataset(\n",
    "    dataset_name=f\"sentiment-analysis-{now}\",\n",
    "    dataframe=df,\n",
    "    input_keys=[\"text\"],\n",
    "    output_keys=[\"predicted_emotion\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Experiment Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Classify the emotion present in the text below. You should only respond with the name of the emotion, no other words.\n",
    "The emotion must be one of the provided values.\n",
    "\n",
    "Input\n",
    "=======\n",
    "[Text]: {text}\n",
    "[Provided Values]: {emotions}\n",
    "\"\"\"\n",
    "model = \"gpt-4-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def summarize_article_openai(input) -> str:\n",
    "    formatted_prompt_template = template.format(text=input[\"text\"], emotions=emotions)\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"assistant\", \"content\": formatted_prompt_template},\n",
    "        ],\n",
    "    )\n",
    "    assert response.choices\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_eval_client = OpenAI()\n",
    "eval_prompt = \"\"\"\n",
    "Your task is to evaluate whether the predicted emotion below describes the supplied input text. \n",
    "We are also including the correct emotion as a piece of data.\n",
    "\n",
    "Begin Data:\n",
    "[input text]: {input}\n",
    "[correct emotion]: {expected}\n",
    "[predicted emotion]: {output}\n",
    "\n",
    "It's possible that the predicted emotion is another word for the correct emotion, and the two are \n",
    "roughly equivalent. If the two emotions are equivalent, respond with the word 'correct'. If they\n",
    "are note equivalent, respond with the word 'incorrect'. Do not include any other words in your \n",
    "response\n",
    "\"\"\"\n",
    "\n",
    "def llm_as_a_judge_eval(input: str, output: str, expected: str):\n",
    "    formatted_prompt_template = eval_prompt.format(input=input[\"text\"], \n",
    "                                                   output=output, \n",
    "                                                   expected=expected[\"predicted_emotion\"])\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"assistant\", \"content\": formatted_prompt_template},\n",
    "        ],\n",
    "    )\n",
    "    assert response.choices\n",
    "    return 1 if response.choices[0].message.content == \"correct\" else 0\n",
    "\n",
    "def exact_match_eval(output: str, expected: str):\n",
    "    return 1 if output.lower() == expected[\"predicted_emotion\"].lower() else 0\n",
    "\n",
    "EVALUATORS = [exact_match_eval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üêå!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Experiment started.\n",
      "üì∫ View dataset experiments: https://app.phoenix.arize.com/datasets/RGF0YXNldDoy/experiments\n",
      "üîó View this experiment: https://app.phoenix.arize.com/datasets/RGF0YXNldDoy/compare?experimentId=RXhwZXJpbWVudDox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running tasks |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 (100.0%) | ‚è≥ 00:10<00:00 |  3.61s/it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Task runs completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üêå!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Evaluation started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running experiment evaluations |          | 0/3 (0.0%) | ‚è≥ 00:00<? | ?it/sc:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\utilities\\client.py:54: UserWarning: The Phoenix server (6.0.0) and client (6.1.0) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n",
      "running experiment evaluations |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 (100.0%) | ‚è≥ 00:02<00:00 |  1.15it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó View this experiment: https://app.phoenix.arize.com/datasets/RGF0YXNldDoy/compare?experimentId=RXhwZXJpbWVudDox\n",
      "\n",
      "Experiment Summary (12/07/24 09:14 PM +0530)\n",
      "--------------------------------------------\n",
      "          evaluator  n  n_scores  avg_score\n",
      "0  exact_match_eval  3         3        1.0\n",
      "\n",
      "Tasks Summary (12/07/24 09:14 PM +0530)\n",
      "---------------------------------------\n",
      "   n_examples  n_runs  n_errors\n",
      "0           3       3         0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.experiments import run_experiment\n",
    "\n",
    "experiment_results = run_experiment(\n",
    "    dataset,\n",
    "    summarize_article_openai,\n",
    "    experiment_name=\"initial-template\",\n",
    "    experiment_description=\"first experiment using a simple prompt template\",\n",
    "    experiment_metadata={\"vendor\": \"openai\", \"model\": \"gpt4o\"},\n",
    "    evaluators=EVALUATORS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify Task to use a New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def summarize_article_openai(input) -> str:\n",
    "    formatted_prompt_template = template.format(text=input[\"text\"], emotions=emotions)\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"assistant\", \"content\": formatted_prompt_template},\n",
    "        ],\n",
    "    )\n",
    "    assert response.choices\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.experiments import run_experiment\n",
    "\n",
    "experiment_results = run_experiment(\n",
    "    dataset,\n",
    "    summarize_article_openai,\n",
    "    experiment_name=\"new-model\",\n",
    "    experiment_description=\"second experiment using a new model\",\n",
    "    experiment_metadata={\"vendor\": \"openai\", \"model\": \"gpt4o-mini\"},\n",
    "    evaluators=EVALUATORS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify Task to Use a Third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "client = Anthropic()\n",
    "anthropic_model = \"claude-3-5-sonnet-20240620\"\n",
    "\n",
    "def summarize_article_anthropic(input: str):\n",
    "    formatted_prompt_template = template.format(text=input[\"text\"], emotions=emotions)\n",
    "    message = client.messages.create(\n",
    "        model=anthropic_model,\n",
    "        max_tokens=1024,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt_template}],\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\utilities\\client.py:54: UserWarning: The Phoenix server (6.0.0) and client (6.1.0) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n",
      "üêå!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Experiment started.\n",
      "üì∫ View dataset experiments: https://app.phoenix.arize.com/datasets/RGF0YXNldDoy/experiments\n",
      "üîó View this experiment: https://app.phoenix.arize.com/datasets/RGF0YXNldDoy/compare?experimentId=RXhwZXJpbWVudDoy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running tasks |          | 0/3 (0.0%) | ‚è≥ 00:00<? | ?it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\experiments\\functions.py\", line 238, in sync_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MSI KATANA\\AppData\\Local\\Temp\\ipykernel_48388\\2276699426.py\", line 7, in summarize_article_anthropic\n",
      "    message = client.messages.create(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\resources\\messages.py\", line 888, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\_base_client.py\", line 1279, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\_base_client.py\", line 956, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\_base_client.py\", line 1060, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "anthropic.AuthenticationError: Error code: 401 - {'type': 'error', 'error': {'type': 'authentication_error', 'message': 'invalid x-api-key'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTAx', repetition 1\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running tasks |‚ñà‚ñà‚ñà‚ñé      | 1/3 (33.3%) | ‚è≥ 00:03<00:07 |  3.71s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\experiments\\functions.py\", line 238, in sync_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MSI KATANA\\AppData\\Local\\Temp\\ipykernel_48388\\2276699426.py\", line 7, in summarize_article_anthropic\n",
      "    message = client.messages.create(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\resources\\messages.py\", line 888, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\_base_client.py\", line 1279, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\_base_client.py\", line 956, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\_base_client.py\", line 1060, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "anthropic.AuthenticationError: Error code: 401 - {'type': 'error', 'error': {'type': 'authentication_error', 'message': 'invalid x-api-key'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTAy', repetition 1\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running tasks |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 (66.7%) | ‚è≥ 00:04<00:02 |  2.24s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\experiments\\functions.py\", line 238, in sync_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MSI KATANA\\AppData\\Local\\Temp\\ipykernel_48388\\2276699426.py\", line 7, in summarize_article_anthropic\n",
      "    message = client.messages.create(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\resources\\messages.py\", line 888, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\_base_client.py\", line 1279, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\_base_client.py\", line 956, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\anthropic\\_base_client.py\", line 1060, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "anthropic.AuthenticationError: Error code: 401 - {'type': 'error', 'error': {'type': 'authentication_error', 'message': 'invalid x-api-key'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTAz', repetition 1\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running tasks |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 (100.0%) | ‚è≥ 00:06<00:00 |  2.16s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Task runs completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üêå!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Evaluation started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\experiments\\functions.py\", line 503, in sync_evaluate_run\n",
      "    result = evaluator.evaluate(\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\experiments\\evaluators\\utils.py\", line 215, in evaluate\n",
      "    result = func(*bound_signature.args, **bound_signature.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MSI KATANA\\AppData\\Local\\Temp\\ipykernel_48388\\3847397930.py\", line 32, in exact_match_eval\n",
      "    return 1 if output.lower() == expected[\"predicted_emotion\"].lower() else 0\n",
      "                ^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'lower'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: evaluator failed for example id 'RGF0YXNldEV4YW1wbGU6MTAx', repetition 1\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\utilities\\client.py:54: UserWarning: The Phoenix server (6.0.0) and client (6.1.0) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n",
      "                                                                    \n",
      "running tasks |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 (100.0%) | ‚è≥ 00:08<00:00 |  2.16s/it        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retries exhausted after 1 attempts: Client error '422 unknown' for url 'https://app.phoenix.arize.com/v1/experiment_evaluations'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/422\n",
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\experiments\\functions.py\", line 503, in sync_evaluate_run\n",
      "    result = evaluator.evaluate(\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\experiments\\evaluators\\utils.py\", line 215, in evaluate\n",
      "    result = func(*bound_signature.args, **bound_signature.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MSI KATANA\\AppData\\Local\\Temp\\ipykernel_48388\\3847397930.py\", line 32, in exact_match_eval\n",
      "    return 1 if output.lower() == expected[\"predicted_emotion\"].lower() else 0\n",
      "                ^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'lower'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: evaluator failed for example id 'RGF0YXNldEV4YW1wbGU6MTAy', repetition 1\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \n",
      "running tasks |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 (100.0%) | ‚è≥ 00:09<00:00 |  2.16s/it                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retries exhausted after 1 attempts: Client error '422 unknown' for url 'https://app.phoenix.arize.com/v1/experiment_evaluations'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/422\n",
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\experiments\\functions.py\", line 503, in sync_evaluate_run\n",
      "    result = evaluator.evaluate(\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI KATANA\\Documents\\GITHUB_FULL_REPO\\Phoenix\\phonex\\Lib\\site-packages\\phoenix\\experiments\\evaluators\\utils.py\", line 215, in evaluate\n",
      "    result = func(*bound_signature.args, **bound_signature.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MSI KATANA\\AppData\\Local\\Temp\\ipykernel_48388\\3847397930.py\", line 32, in exact_match_eval\n",
      "    return 1 if output.lower() == expected[\"predicted_emotion\"].lower() else 0\n",
      "                ^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'lower'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: evaluator failed for example id 'RGF0YXNldEV4YW1wbGU6MTAz', repetition 1\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \n",
      "running tasks |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 (100.0%) | ‚è≥ 00:10<00:00 |  2.16s/it                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retries exhausted after 1 attempts: Client error '422 unknown' for url 'https://app.phoenix.arize.com/v1/experiment_evaluations'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/422\n",
      "\n",
      "üîó View this experiment: https://app.phoenix.arize.com/datasets/RGF0YXNldDoy/compare?experimentId=RXhwZXJpbWVudDoy\n",
      "\n",
      "Experiment Summary (12/07/24 09:16 PM +0530)\n",
      "--------------------------------------------\n",
      "          evaluator  n\n",
      "0  exact_match_eval  3\n",
      "\n",
      "Tasks Summary (12/07/24 09:16 PM +0530)\n",
      "---------------------------------------\n",
      "   n_examples  n_runs  n_errors  \\\n",
      "0           3       3         3   \n",
      "\n",
      "                                           top_error  \n",
      "0  AuthenticationError(\"Error code: 401 - {'type'...  \n"
     ]
    }
   ],
   "source": [
    "from phoenix.experiments import run_experiment\n",
    "\n",
    "experiment_results = run_experiment(\n",
    "    dataset,\n",
    "    summarize_article_anthropic,\n",
    "    experiment_name=\"third-model\",\n",
    "    experiment_description=\"third experiment, with a new model\",\n",
    "    experiment_metadata={\"vendor\": \"anthropic\", \"model\": \"claude-3-sonnet\"},\n",
    "    evaluators=EVALUATORS,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phonex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
